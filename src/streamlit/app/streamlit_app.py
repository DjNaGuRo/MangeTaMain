"""Application Streamlit principale (plots + textes explicatifs)."""

import streamlit as st
import pandas as pd
import numpy as np
import sys, inspect
from pathlib import Path

import yaml


# ---------------------------------------------------------------------------
# Setup chemin src
# ---------------------------------------------------------------------------
def _ensure_src_on_path():
    root = Path(__file__).resolve()
    for p in [root, *root.parents]:
        if (p / "pyproject.toml").exists():
            project_root = p
            break
    else:
        project_root = Path.cwd()
    for add in (project_root, project_root / "src"):
        s = str(add)
        if s not in sys.path:
            sys.path.insert(0, s)
    return project_root


PROJECT_ROOT = _ensure_src_on_path()

# ---------------------------------------------------------------------------
# Imports visualisation
# ---------------------------------------------------------------------------
try:
    from src.data_visualization import (
        rating_distribution,
        recipe_mean_rating_distribution,
        top_users_by_activity,
        user_mean_rating_distribution,
        user_count_vs_mean_rating,
        activity_bucket_bar,
        analyze_contributors,
        statistique_descriptive,
        plot_prep_time_distribution,
        plot_ingredient,
        plot_n_steps_distribution,
        analyse_tags,
        plot_tags_distribution,
        plot_nutrition_distribution,
        analyze_ingredients_vectorized,
        minutes_group_negative_reviews_bar,
        spearman_correlation,
        plot_ingredients_vs_negative_score,
        analyze_tags_correlation,
        nutrition_correlation_analysis,
        get_most_negative_user,
        plot_minutes_ningredients_nsteps,
    )
    from src.preprocessing import (
        detect_missing_values,
        detect_duplicates,
        remove_outliers_nutrition,
        clean_review,
        is_negative_sentence,
        binary_sentiment,
    )

    DV_OK = True
    DV_ERR = None
except Exception as e:
    DV_OK = False
    DV_ERR = e


# ---------------------------------------------------------------------------
# Chargement des donn√©es (cache)
# ---------------------------------------------------------------------------
@st.cache_data
def _read_csv(rel):
    p = PROJECT_ROOT / rel
    if not p.exists():
        return None
    try:
        return pd.read_csv(p)
    except Exception:
        return None


@st.cache_data(show_spinner=False)
def load_all_datasets():
    """Charge une seule fois toutes les donn√©es utiles et les retourne dans un dict."""
    merged_df = _read_csv("data/processed/merged_cleaned.csv")
    interactions = _read_csv("data/processed/interactions_cleaned.csv")
    clean_recipes = _read_csv("data/processed/recipes_cleaned.csv")
    raw_recipes = _read_csv("data/raw/RAW_recipes.csv")
    raw_interactions = _read_csv("data/raw/RAW_interactions.csv")
    return {
        "merged": merged_df,
        "interactions": interactions,
        "clean_recipes": clean_recipes,
        "raw_recipes": raw_recipes,
        "raw_interactions": raw_interactions,
    }


def get_ds():
    """Acc√®s centralis√© aux datasets (dans session_state)."""
    if "ds" not in st.session_state:
        st.session_state["ds"] = load_all_datasets()
    return st.session_state["ds"]


# ---------------------------------------------------------------------------
# Th√®me
# ---------------------------------------------------------------------------
def set_custom_theme(theme="Clair"):
    if theme == "Sombre":
        colors = {
            "primary": "#ffffff",
            "secondary": "#f0f0f0",
            "background": "#181a1b",
            "text": "#e0e0e0",
            "header_gradient": "linear-gradient(135deg,#444,#111)",
            "sidebar_gradient": "linear-gradient(180deg,#333,#111)",
            "button_text": "#ffffff",
        }
    else:
        colors = {
            "primary": "#667eea",
            "secondary": "#764ba2",
            "background": "#F0F2F6",
            "text": "#2C3E50",
            "header_gradient": "linear-gradient(135deg,#667eea,#764ba2)",
            "sidebar_gradient": "linear-gradient(180deg,#667eea,#764ba2)",
            "button_text": "#ffffff",
        }
    st.markdown(
        f"""
    <style>
    .stApp {{background:{colors['background']}; color:{colors['text']};}}
    .main-header {{background:{colors['header_gradient']}; padding:1.4rem; border-radius:14px;
                   color:{colors['button_text']} !important; text-align:center; margin-bottom:1.0rem;}}
    [data-testid="stSidebar"] {{background:{colors['sidebar_gradient']};}}
    [data-testid="stSidebar"] * {{color:#ffffff !important;}}
    .stButton>button {{
        background:{colors['header_gradient']}; color:{colors['button_text']} !important;
        border:none; border-radius:24px; padding:0.55rem 1.3rem; font-weight:600;
    }}
    </style>
    """,
        unsafe_allow_html=True,
    )


# ---------------------------------------------------------------------------
# Textes explicatifs (extraits / synth√®ses notebook)
# ---------------------------------------------------------------------------
MD_MAP = {
    "rating_distribution": (
        "Distribution des ratings: forte concentration sur 4 et 5 ‚Üí biais positif important."
    ),
    "user_mean_rating_distribution": (
        "Moyenne par utilisateur: permet de voir le biais individuel et la dispersion des comportements de notation."
    ),
    "recipe_mean_rating_distribution": (
        "Moyenne par recette: rep√®re les recettes syst√©matiquement sur‚Äë ou sous‚Äënot√©es."
    ),
    "top_users_by_activity": (
        "Top utilisateurs actifs: forte concentration de l‚Äôactivit√© sur quelques comptes tr√®s prolifiques."
    ),
    "user_count_vs_mean_rating": (
        "Relation nombre d‚Äôavis vs note moyenne: beaucoup d‚Äôutilisateurs peu actifs; les plus actifs ont une moyenne √©lev√©e (~4.5‚Äì5)."
    ),
    "activity_bucket_bar": (
        "Segmentation de l‚Äôactivit√© (buckets) pour comparer la note moyenne selon l‚Äôintensit√© de participation."
    ),
    "plot_prep_time_distribution": (
        "Cat√©gorisation temps de pr√©paration: la majorit√© ‚â§ 2h; valeurs extr√™mes (0 ou tr√®s longues) peu influentes globalement."
    ),
    "plot_ingredient": (
        "Analyse ingr√©dients: quelques ingr√©dients dominants (sel, beurre, sucre); Pareto montre forte concentration."
    ),
    "plot_n_steps_distribution": (
        "Nombre d‚Äô√©tapes: distribution et complexit√© proc√©durale; extr√™mes rares."
    ),
    "plot_tags_distribution": (
        "Distribution du nombre de tags par recette: mesure richesse descriptive et diversit√© cat√©gorielle."
    ),
    "plot_nutrition_distribution": (
        "Caract√©ristiques nutritionnelles: dispersion des nutriments cl√©s (calories, sucre, prot√©ines, etc.)."
    ),
    "minutes_group_negative_reviews_bar": (
        "Test influence du temps sur insatisfaction: regroupements courte/moyenne/longue; pas de effet fort observ√©."
    ),
    "plot_ingredients_vs_negative_score": (
        "Nombre d‚Äôingr√©dients vs insatisfaction: absence de corr√©lation notable ‚Üí complexit√© n‚Äôaugmente pas les critiques."
    ),
    "analyze_tags_correlation": (
        "Tags et insatisfaction: certaines cat√©gories (equipment, meat, main-dish) associ√©es √† scores n√©gatifs plus √©lev√©s."
    ),
    "nutrition_correlation_analysis": (
        "Nutrition vs insatisfaction: pas de corr√©lations significatives avec les avis n√©gatifs ou score global."
    ),
}


# --- Chargement commentaires externes (YAML) ---
@st.cache_data
def load_commentary_yaml():
    p = PROJECT_ROOT / "src" / "streamlit" / "app" / "comment.yaml"
    if not p.exists():
        return {}
    try:
        return yaml.safe_load(p.read_text(encoding="utf-8")) or {}
    except Exception:
        return {}


EXTERNAL_COMMENTS = load_commentary_yaml()


def get_comment(func_name: str) -> str:
    # Priorit√© YAML puis MD_MAP
    return EXTERNAL_COMMENTS.get(func_name) or MD_MAP.get(func_name)


PAGES_ORDER = [
    ("üè† Accueil", "home", lambda: show_home_page()),
    ("üìä Donn√©es cleaning", "data", lambda: show_data_page()),
    ("üìà Visualisations", "viz", lambda: show_visualizations()),
]


def _init_page_state():
    if "current_page_idx" not in st.session_state:
        st.session_state.current_page_idx = 0


def _go_delta(delta: int):
    st.session_state.current_page_idx = (
        st.session_state.current_page_idx + delta
    ) % len(PAGES_ORDER)


def _set_page_by_key(page_key: str):
    for i, (_, key, _) in enumerate(PAGES_ORDER):
        if key == page_key:
            st.session_state.current_page_idx = i
            break


def _safe_rerun():
    """Compatibilit√© versions Streamlit."""
    if hasattr(st, "rerun"):
        st.rerun()
    elif hasattr(st, "experimental_rerun"):
        st.experimental_rerun()


# ---------------------------------------------------------------------------
# Wrapper rendu (affiche figure + docstring + texte explicatif)
# ---------------------------------------------------------------------------
FAST_MODE = st.session_state.get("FAST_MODE", False)


def render_viz(
    label,
    func,
    df,
    show_doc=False,
    expander=True,
    sample_if_fast: int | None = None,
    **kwargs,
):
    if df is None:
        st.warning(f"{label}: dataset manquant")
        return
    block = st.expander(label, expanded=not expander) if expander else st.container()
    with block:
        if FAST_MODE and sample_if_fast and len(df) > sample_if_fast:
            df = df.sample(sample_if_fast, random_state=42)
        try:
            fig = func(df, return_fig=True, **kwargs)
            if fig is None:
                st.info("Figure non retourn√©e.")
                return
            st.pyplot(fig, use_container_width=True)
            if show_doc:
                doc = inspect.getdoc(func)
                comment = get_comment(func.__name__)
                if doc or comment:
                    with st.container():
                        if doc:
                            st.caption(doc)
                        if comment:
                            st.markdown(comment)
            if FAST_MODE:
                st.caption("FAST_MODE actif (√©chantillonnage).")
        except Exception as e:
            st.error(f"Erreur: {e}")


# ---------------------------------------------------------------------------
# Page Accueil
# ---------------------------------------------------------------------------
def show_home_page():
    recipes_df = get_ds()["clean_recipes"]
    raw_interactions = get_ds()["raw_interactions"]

    st.markdown("## INTRODUCTION")
    st.markdown(
        """Notre √©quipe compos√© de Guy, Mohamed, Leonnel, Omar et Osman avons d√©cid√© de travailler sur le projet MangeTaMain sur la probl√©matique 
            du **taux d'insatisfaction des recettes** en nous basant sur 2 tables : les recettes et les interactions utilisateurs (notes, avis).
            Voici un aper√ßu de la table recette :
                """
    )

    st.dataframe(recipes_df.head(5), use_container_width=True)

    st.markdown("""et voici un aper√ßu de la table interactions :""")

    st.dataframe(raw_interactions.head(5), use_container_width=True)

    st.markdown(
        """Le travaille se d√©cline en plusieurs √©tapes :  
                - **data_cleaning** : comprendre la structure, les types de donn√©es, les valeurs manquantes, les valeurs aberrantes, etc.  
                - **Analyse univari√©e** : analyse statistique descriptive et visualisations pour comprendre les tendances, les distributions, les corr√©lations, etc.  
                - **Analyse bivari√©e** : exploration des relations entre les variables, identification des facteurs influen√ßant le taux d'insatisfaction.  
                - **Ouverture** : Conclusion et suggestions pour la poursuite de l'analyse  
                """
    )

    # Boutons navigation rapides
    st.markdown("### Navigation rapide")
    c1, c2 = st.columns(2)
    with c1:
        if st.button("üìä Aller √† la page data cleaning"):
            _set_page_by_key("data")
            _safe_rerun()
    with c2:
        if st.button("üìà Aller aux Visualisations"):
            _set_page_by_key("viz")
            _safe_rerun()


# ---------------------------------------------------------------------------
# Page Data cleaning
# ---------------------------------------------------------------------------
def show_data_page():
    st.markdown("## Data cleaning pour la table interactions")
    df_raw_interactions = get_ds()["raw_interactions"]
    if df_raw_interactions is None:
        st.error("Donn√©es non disponibles.")
        return

    st.markdown(
        """Il est primordial de nettoyer les donn√©es avant de proc√©der √† toute analyse. Int√©ressons nous aux valeurs manquantes :"""
    )

    missing_interactions = detect_missing_values(df_raw_interactions)
    missing_df = (
        missing_interactions[missing_interactions > 0]
        .sort_values(ascending=False)
        .to_frame(name="missing")
        .astype(int)
    )

    if missing_df.empty:
        st.success("Aucune valeur manquante d√©tect√©e.")
    else:
        with st.expander("Nombre de valeurs manquantes", expanded=False):
            for col, val in missing_df["missing"].items():
                st.write(f"{col}: {val}")

    # imputation
    st.markdown(
        """Nous avons d√©cid√© d'imputer les valeurs manquantes de la colonne 'review' par :  
        - "Excellent recipe! Loved it!" si rating = 5  
        - "Great recipe, will make again." si rating = 4  
        - "Good recipe, but could be improved." si rating = 3  
        - "Not my favorite."" si rating = 2  
        - "Did not like this recipe at all." si rating = 1  
        
        La proportion de valeurs manquantes est de 0.01%, donc cette imputation n'affectera pas significativement l'analyse globale.  
    Nous avons √©galement v√©rifi√© qu'il n'y avait pas de doublons dans le dataset."""
    )

    st.markdown("### Analyse de la colonne rating")

    st.markdown(
        """
    Les notes donn√©es par les utilisateurs sont comprises entre 1 et 5. Cependant, nous observons que plusieurs lignes du jeu de donn√©es pr√©sentent une note √©gale √† 0 (rating = 0), tout en contenant un commentaire textuel (review) souvent positif ou n√©gatif.
    Cette situation est incoh√©rente : une note de 0 ne correspond pas √† une appr√©ciation valide sur une √©chelle de 1 √† 5, et le contenu des commentaires indique que les utilisateurs ont bien exprim√© une opinion sur la recette.

    Nous en d√©duisons que la valeur 0 ne traduit pas une mauvaise note, mais plut√¥t l‚Äôabsence de note ‚Äî autrement dit, une valeur manquante cod√©e par 0.

    En cons√©quence, nous consid√©rons toutes les notes √©gales √† 0 comme valeurs manquantes et nous les rempla√ßons par NaN afin de ne pas biaiser les statistiques descriptives ni les calculs de moyennes.
    Cela revient √† interpr√©ter ces cas comme des utilisateurs ayant laiss√© un commentaire sans attribuer de note chiffr√©e.
                """
    )

    st.markdown("### Evaluation de la proportion d'avis n√©gatifs")

    st.markdown(
        """
    Notre √©tude portant sur les caract√©ristiques des recettes g√©n√©rant des avis n√©gatifs, nous cherchons dans un premier temps √† identifier les avis n√©gatis.

    **PROCEDURE :**

    Au vue de la proportion tr√®s importante d'avis positif dans le dataset, nous admettrons qu'une recette est moins appr√©ci√©e au moins 1 avis sur cette recette pr√©sente des suggestions ou des axes d'am√©liorations. En se basant sur ce constat, 2 features pourraient nous des informations. Dans un premier temps, nous allons consid√©rer les recettes qui ont des avis not√©s √† 3 ou moins et dans un second temps nous allons nous concentrer sur commentaires portant au moins un aspect n√©gatif pour les avis ayant une note de 0 (absencce de note) et 4. Nous nous interesserons pas aux commentaires des recettes ayant re√ßu uniquement des notes de 5.
                """
    )

    st.markdown(
        """Nous avons donc commenc√© par isoler les avis avec une note de 3 ou moins :"""
    )

    ### CREATION DE LA COLONNE BINARY SENTIMENT

    df_raw_interactions["binary_sentiment"] = df_raw_interactions["rating"].apply(
        lambda x: 1 if x in [1, 2, 3] else 0
    )

    # Seed √©chantillon dans session_state
    if "binary_sample_seed" not in st.session_state:
        st.session_state.binary_sample_seed = 0

    interactions_binary_sentiment = st.multiselect(
        "Colonnes √† afficher",
        df_raw_interactions.columns.tolist(),
        default=df_raw_interactions.columns.tolist()[:8],
    )

    # √âchantillon stable (tant que seed inchang√©)
    sample_df = df_raw_interactions[interactions_binary_sentiment].sample(
        min(5, len(df_raw_interactions)),
        random_state=st.session_state.binary_sample_seed,
    )
    st.dataframe(sample_df, use_container_width=True)

    col_btn, col_info = st.columns([1, 3])
    with col_btn:
        if st.button("üîÑ Rafra√Æchir √©chantillon"):
            st.session_state.binary_sample_seed += 1
            _safe_rerun()
    with col_info:
        st.caption(f"Seed √©chantillon: {st.session_state.binary_sample_seed}")

    st.markdown(
        """Nous pouvons observer que les avis avec un rating de 1 √† 3 ont bien un binary_sentiment de 1."""
    )

    st.markdown(
        """Passons maintenant aux avis avec un rating de 0 ou 4 :
                Comme expliqu√© pr√©c√©demment, les avis avec un rating de 0 sont consid√©r√©s comme une absence de note, mais contiennent des commentaires textuels qui peuvent nous donner une information sur l'insatisfaction de l'utilisateur concernant la recette.  
                De plus les avis avec un rating de 4 peuvent √©galement contenir des commentaires n√©gatifs, car une note de 4 n'est pas parfaite et peut refl√©ter certaines insatisfactions. Exemple : "it was an amazing dish, we appreciated it so much, [...], but it was too sweet", ceci est une proposition d'am√©lioration de la recette par l'utilisateur et compte donc comme un avis n√©gatif. Nous allons donc analyser les commentaires textuels (review) des avis avec un rating de 0 ou 4 pour d√©tecter la pr√©sence d'aspects n√©gatifs.  
                Pour cela nous allons faire de la tokenization et de l'analyse de sentiment afin d'identifier les phrases n√©gatives dans les commentaires.  
                Enfin apr√®s avoir identifi√© les commentaires n√©gatifs, nous mettons √† jour la colonne binary_sentiment dans le dataset original.
                """
    )

    # ---------------------------------------------------------------------------
    # Cleaning de la table recipes
    # ---------------------------------------------------------------------------

    st.markdown("### Data cleaning pour la table recettes")

    df_raw_recipes = get_ds()["raw_recipes"]
    if df_raw_recipes is None:
        st.error("Donn√©es non disponibles.")
        return

    missing_recipes = detect_missing_values(df_raw_recipes)
    missing_recipes_df = (
        missing_recipes[missing_recipes > 0]
        .sort_values(ascending=False)
        .to_frame(name="missing")
        .astype(int)
    )

    if missing_recipes_df.empty:
        st.success("Aucune valeur manquante d√©tect√©e.")
    else:
        with st.expander("Nombre de valeurs manquantes", expanded=False):
            for col, val in missing_recipes_df["missing"].items():
                st.write(f"{col}: {val}")

    # imputation
    st.markdown(
        """Nous obervons que les donn√©es manquantes sont dans la colonne 'description' de la recette. Cette variable n'est pas utile dans notre √©tude, donc pour ne pas avoir de valeurs manquantes 
        nous avons d√©cid√© d'imputer les valeurs manquantes par "No_description". Nous avons √©galement supprim√© la ligne dont l'information dans "name" √©tait manquante.
        Nous avons √©galement v√©rifi√© qu'il n'y avait pas de doublons dans le dataset."""
    )

    st.markdown(""" **√©tude des valeurs extr√™mes:**  """)

    render_viz(
        "boxplot des minutes, n_ingredients et n_steps",
        plot_minutes_ningredients_nsteps,
        df_raw_recipes,
    )

    st.markdown(
        """Nous pouvons remarquer la pr√©sence de valeurs extr√™mes dans les 3 colonnes, en particulier dans la colonne temps de pr√©paration
                """
    )

    st.markdown(
        """Pour la colonne *minutes* nous d√©cidons de ne pas garder les recettes qui ont plus de 1 mois en temps
                de pr√©paration, ces valeurs repr√©sentent 0.03% du dataset"""
    )

    st.markdown("""**colonne nutrition**""")

    st.markdown(
        """Pour la colonne nutrition nous faisons du feature engineering : nous allons split les valeurs nutritionelles respectivement par 'calories', 'total_fat', 'sugar', 'sodium', 'protein', 'saturated_fat', 'carbohydrates' """
    )

    st.markdown("""voici un aper√ßu de la table apr√®s le split""")

    df_raw_recipes[
        [
            "calories",
            "total_fat",
            "sugar",
            "sodium",
            "protein",
            "saturated_fat",
            "carbohydrates",
        ]
    ] = df_raw_recipes.nutrition.str.split(",", expand=True)

    splitted_recipes = st.multiselect(
        "Colonnes √† afficher",
        df_raw_recipes.columns.tolist(),
        default=df_raw_recipes.columns.tolist()[:19],
    )
    st.dataframe(df_raw_recipes[splitted_recipes].head(5), use_container_width=True)

    st.markdown(
        """ Pour chacune des valeurs nutritionnelles, il √©galement est possible de remarquer des valeurs tr√®s extr√™mes ! Les valeurs max sont des valeurs ab√©rrantes cependant d'autre valeurs tel que les recettes √† plus de 3 000 calories sont potentiellement des recettes avec des scores nutritionnels calcul√©s pour la totalit√© de la recette et non normalis√© (par exemple par portion). les valeurs nutritionnels pour une portion sont d'environs 200~800 kcal. Comme nous n'avons pas d'information sur la quantit√© consid√©r√© (portion ou recette total), on d√©cide donc de supprimer les recettes √† plus de 3000 calories sachant qu'ils repr√©sentent qu'un tr√®s petit pourcentage de recette.  

        De m√™me les valeurs nutrionnels pour :  
        - les glucides : 20 ~ 100 g > suppression des recettes √† plus de 500g  
        - prot√©ines : 10 ~ 100 g > suppression des recettes √† plus de 500g  
        - Sodium : 200 ~ 1500 mg > suppression des recettes √† plus de 5000mg  """
    )


# ---------------------------------------------------------------------------ra
# Page Visualisations
# ---------------------------------------------------------------------------
def show_visualizations():
    st.markdown("## Visualisations")

    df_merged = get_ds()["merged"]
    df_inter = get_ds()["interactions"]
    df_clean_recipes = get_ds()["clean_recipes"]

    tabs = st.tabs(
        ["Distribution", "Utilisateurs", "Recettes", "Corr√©lations", "Nutrition"]
    )

    with tabs[0]:
        render_viz("Distribution brute des notes", rating_distribution, df_inter)

        st.markdown(""" Distribution brute des notes """)

        render_viz(
            "Moyennes des notes par recette", recipe_mean_rating_distribution, df_inter
        )
        render_viz(
            "Moyennes des notes par utilisateur",
            user_mean_rating_distribution,
            df_inter,
        )
        
        render_viz(
            "Analyse des contributeurs des recettes",
            analyze_contributors,
            df_clean_recipes,
        )

    with tabs[1]:
        render_viz("Top utilisateurs actifs", top_users_by_activity, df_inter)
        render_viz("Activit√© (buckets) vs note moyenne", activity_bucket_bar, df_inter)
        render_viz(
            "Nombre d'avis vs moyenne (√©chantillon)",
            user_count_vs_mean_rating,
            df_inter,
            sample=2500,
        )

    with tabs[2]:
        render_viz(
            "Temps de pr√©paration (cat√©gories)", plot_prep_time_distribution, df_merged
        )
        render_viz(
            "Ingr√©dients + Pareto",
            plot_ingredient,
            df_clean_recipes if df_clean_recipes is not None else df_merged,
        )
        render_viz("Nombre d'√©tapes", plot_n_steps_distribution, df_merged)
        if df_merged is not None and "tags" in df_merged.columns:
            render_viz("Distribution des tags", plot_tags_distribution, df_merged)
            if st.checkbox("Afficher stats tags"):
                try:
                    st.dataframe(analyse_tags(df_merged))
                except Exception as e:
                    st.error(e)
        if df_clean_recipes is not None and st.checkbox("Stats ingr√©dients vectoris√©s"):
            st.dataframe(analyze_ingredients_vectorized(df_clean_recipes))

    with tabs[3]:
        if df_merged is not None:
            render_viz(
                "Minutes vs insatisfaction (groupes)",
                minutes_group_negative_reviews_bar,
                df_merged,
            )
            if {"n_ingredients", "negative_reviews"}.issubset(df_merged.columns):
                render_viz(
                    "Ingr√©dients vs insatisfaction",
                    plot_ingredients_vs_negative_score,
                    df_merged,
                )
            if "tags" in df_merged.columns and {
                "negative_reviews",
                "total_reviews",
            }.issubset(df_merged.columns):
                render_viz(
                    "Tags vs insatisfaction", analyze_tags_correlation, df_merged
                )

    with tabs[4]:
        needed = {
            "calories",
            "sugar",
            "protein",
            "sodium",
            "total_fat",
            "carbohydrates",
        }
        if df_merged is None or not needed.issubset(df_merged.columns):
            st.warning("Colonnes nutrition manquantes.")
        else:
            render_viz("Distribution nutrition", plot_nutrition_distribution, df_merged)
            render_viz(
                "Corr√©lations nutrition ‚Üî insatisfaction",
                nutrition_correlation_analysis,
                df_merged,
            )


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------
def main():
    st.set_page_config(page_title="MangeTaMain", page_icon="üçΩÔ∏è", layout="wide")
    _init_page_state()
    if "theme" not in st.session_state:
        st.session_state.theme = "Clair"
    set_custom_theme(st.session_state.theme)

    ds = get_ds()

    # Barre sup√©rieure avec chevrons
    top_left, top_center, top_right = st.columns([0.7, 5, 0.7])
    with top_left:
        if st.button("‚óÄ"):
            _go_delta(-1)
            _safe_rerun()
    with top_center:
        label, key, _ = PAGES_ORDER[st.session_state.current_page_idx]
        st.markdown(
            f"<h2 style='text-align:center'>{label}</h2>", unsafe_allow_html=True
        )
    with top_right:
        if st.button("‚ñ∂"):
            _go_delta(1)
            _safe_rerun()

    with st.sidebar:
        st.markdown("### Pages")
        selected = st.radio(
            "Aller √†",
            [lbl for (lbl, _, _) in PAGES_ORDER],
            index=st.session_state.current_page_idx,
        )
        if PAGES_ORDER[st.session_state.current_page_idx][0] != selected:
            for i, (lbl, key, _) in enumerate(PAGES_ORDER):
                if lbl == selected:
                    st.session_state.current_page_idx = i
                    _safe_rerun()
                    break
        st.selectbox(
            "Th√®me",
            ["Clair", "Sombre"],
            index=["Clair", "Sombre"].index(st.session_state.theme),
            key="theme_selector",
            on_change=lambda: st.session_state.update(
                theme=st.session_state.theme_selector
            ),
        )
        if not DV_OK:
            st.caption(f"‚ö†Ô∏è Module viz: KO ({DV_ERR})")

    st.markdown(
        """
    <div class="main-header">
      <h1>üçΩÔ∏è MangeTaMain</h1>
      <p>Analyse des recettes et interactions (plots & explications)</p>
    </div>
    """,
        unsafe_allow_html=True,
    )

    _, _, render = PAGES_ORDER[st.session_state.current_page_idx]
    render()


if __name__ == "__main__":
    main()

## Lancement de l'application

L'application peut √™tre lanc√©e via Docker Compose ou directement avec Streamlit.

**Pr√©paration automatique des donn√©es :**
Au premier lancement, les donn√©es seront automatiquement t√©l√©charg√©es et extraites dans `data/raw` et `data/processed` si elles sont absentes, gr√¢ce √† la fonction `ensure_data` (voir la variable d'environnement `DATA_REMOTE_URL`). Il n'est plus n√©cessaire de placer manuellement les fichiers ou d'ex√©cuter les notebooks pour pr√©parer les donn√©es.

1. Lancez l'application via Docker Compose :
```bash
docker compose up
```

2. Lancez l'application via Streamlit :
```bash
poetry run streamlit run src/streamlit/app/streamlit_app.py
```

L'application sera disponible sur http://localhost:8501

## Navigation dans l'interface

L'application est organis√©e en plusieurs pages :

üè† Accueil

Pr√©sentation du projet et aper√ßu des donn√©es


üìä Donn√©es cleaning

- D√©tection des valeurs manquantes
- Traitement des doublons
- Suppression des valeurs aberrantes
- Imputation des donn√©es manquantes


üìà Visualisations

- Distribution des ratings
- Analyse des contributeurs
- Corr√©lations nutritionnelles
- Analyse de sentiment des avis


üìù Conclusion

Synth√®se des r√©sultats et perspectives


## Utilisation des notebooks (optionnel)

Les notebooks du dossier `notebooks/` servent √† l'exploration, au nettoyage ou √† la visualisation avanc√©e des donn√©es. Leur utilisation est facultative, car l'application g√®re automatiquement le t√©l√©chargement et la pr√©paration des donn√©es.

#### Notebook principal
```bash
poetry run jupyter notebook notebooks/data_cleaning.ipynb
```

#### Notebook de visualisation
```bash
poetry run jupyter notebook notebooks/data_vizualisation.ipynb
```

## Tests

#### Lancer les tests unitaires :

```bash
poetry run pytest tests/ -v
```

## Linting et formatage

```bash
# Formatage avec Black
poetry run black src/

# Linting avec flake8
poetry run flake8 src/ --max-line-length=88
```

